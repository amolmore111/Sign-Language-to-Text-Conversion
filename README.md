# Sign-Language-to-Text-Conversion
Sign language, being one of the oldest and most natural forms of communication, serves as a crucial means of expression for individuals with hearing and speech impairments. Deaf and dumb (D&M) individuals heavily rely on sign language for communication, given their limitations in using spoken languages. In this context, we are introducing a real-time method utilizing neural networks for finger spelling based on American Sign Language (ASL). Automatic human gesture recognition, especially from camera images, has become an intriguing area for developing computer vision applications. Recognizing hand gestures in real-time from camera images can significantly enhance communication for individuals with hearing and speech impairments. The proposed method employs Long Short-Term Memory (LSTM) to recognize hand gestures associated with American Sign Language.


![image](https://github.com/amolmore111/Sign-Language-to-Text-Conversion/assets/123639865/8704adac-10e3-4e7a-90d7-6dd9c11cae78)


In our project we basically focus on producing a model which can recognise Finger spelling based hand gestures in order to form a complete word by combining each gesture.
The gestures we aim to train are as given in the image below.

#Signs

![Sign Language signs](https://github.com/amolmore111/Sign-Language-to-Text-Conversion/assets/123639865/4183904f-f0eb-42f1-b5a7-d04a79272c04)

#Motivation:
Existing sign language recognition systems lack real-time capabilities, adaptability to varied environments, and holistic solutions, hindering seamless communication for Deaf and hardof-hearing individuals.

#Objectives:
 Achieve real-time recognition of finger-spelling gestures.
 Ensure system performance in diverse real-world settings.
 Optimize the use of Convolutional Neural Networks (CNNs) for gesture recognition.
 Provide a holistic communication solution incorporating real-time translation and userfriendly interfaces.
 Foster social inclusion and understanding through improved communication accessibility.

#Scope: 
 Exploration and implementation of various background subtraction algorithms.
 Aim to enhance gesture recognition accuracy, particularly in complex backgrounds.
 Research and implementation of preprocessing techniques to improve gesture prediction in low light conditions.
 Focus on achieving higher accuracy in challenging lighting environments
