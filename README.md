# Sign-Language-to-Text-Conversion
Sign language, being one of the oldest and most natural forms of communication, serves as a crucial means of expression for individuals with hearing and speech impairments. Deaf and dumb (D&M) individuals heavily rely on sign language for communication, given their limitations in using spoken languages. In this context, we are introducing a real-time method utilizing neural networks for finger spelling based on American Sign Language (ASL). Automatic human gesture recognition, especially from camera images, has become an intriguing area for developing computer vision applications. Recognizing hand gestures in real-time from camera images can significantly enhance communication for individuals with hearing and speech impairments. The proposed method employs Long Short-Term Memory (LSTM) to recognize hand gestures associated with American Sign Language.

![image](https://github.com/amolmore111/Sign-Language-to-Text-Conversion/assets/123639865/db59effc-8249-4fe4-bac4-ee6b9a468b9d)

In our project we basically focus on producing a model which can recognise Finger spelling based hand gestures in order to form a complete word by combining each gesture.
The gestures we aim to train are as given in the image below.

#Signs
![image](https://github.com/amolmore111/Sign-Language-to-Text-Conversion/assets/123639865/47983dbe-1817-4838-9a03-9bbdc5000067)
